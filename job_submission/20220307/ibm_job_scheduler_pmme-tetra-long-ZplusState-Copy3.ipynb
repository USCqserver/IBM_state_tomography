{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Run Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-utec1m6f because the default path (/home/haimeng/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "from qiskit import *\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "#you have to load some account to start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haimeng/anaconda3/envs/newest_qiskit/lib/python3.8/site-packages/qiskit/providers/ibmq/ibmqfactory.py:109: UserWarning: Timestamps in IBMQ backend properties, jobs, and job results are all now in local time instead of UTC.\n",
      "  warnings.warn('Timestamps in IBMQ backend properties, jobs, and job results '\n"
     ]
    }
   ],
   "source": [
    "# IBMQ.disable_account() \n",
    "# IBMQ.disable_account()\n",
    "token0 = '316cca1ff42067b9901b6a9e90ca76496e76b4a73139954176c6fe31a45572fcd37089924cbe5c41edb96a9b4c0e92e44451ed350e2a7e45dc809d26cd752eed'\n",
    "provider = IBMQ.enable_account(token0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the files that need to be run \n",
    "The old setup works with only one folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuitPath = r\"/home/haimeng/LocalProjects/IBM-PMME/Circuits\"\n",
    "device = \"ibmq_bogota\"\n",
    "datastr_list = ['20220228', '20220301', '20220302']\n",
    "QS = 'ZminusState'\n",
    "isDD = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../')\n",
    "from submit_qasm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchFiles = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batchFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/haimeng/LocalProjects/IBM-PMME/Circuits/ibmq_bogota/20220302/MeasMainqFreeLongXY4_Q0_tetra0_QS4_ZminusState/MeasMainqFreeLongXY4_Q0_tetra0_QS4_ZminusState_20220302_ibmq_bogota_numXYXYseq=576_obsZ.qasm\n",
      "/home/haimeng/LocalProjects/IBM-PMME/Circuits/ibmq_bogota/20220302/MeasMainqFreeLongXY4_Q0_tetra0_QS4_ZminusState/MeasMainqFreeLongXY4_Q0_tetra0_QS4_ZminusState_20220302_ibmq_bogota_numXYXYseq=36_obsZ.qasm\n",
      "/home/haimeng/LocalProjects/IBM-PMME/Circuits/ibmq_bogota/20220302/MeasMainqFreeLongXY4_Q0_tetra1_QS4_ZminusState/MeasMainqFreeLongXY4_Q0_tetra1_QS4_ZminusState_20220302_ibmq_bogota_numXYXYseq=252_obsY.qasm\n",
      "/home/haimeng/LocalProjects/IBM-PMME/Circuits/ibmq_bogota/20220302/MeasMainqFreeLongXY4_Q0_tetra2_QS4_ZminusState/MeasMainqFreeLongXY4_Q0_tetra2_QS4_ZminusState_20220302_ibmq_bogota_numXYXYseq=792_obsX.qasm\n",
      "/home/haimeng/LocalProjects/IBM-PMME/Circuits/ibmq_bogota/20220302/MeasMainqFreeLongXY4_Q0_randomState_QS4_ZminusState/MeasMainqFreeLongXY4_Q0_randomState_QS4_ZminusState_20220302_ibmq_bogota_numXYXYseq=72_obsX.qasm\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(batchFiles[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tetra0\n",
      "tetra0\n",
      "tetra1\n",
      "tetra2\n",
      "randomState\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(batchFiles[i][0].split('/')[-1].split('_')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokens = {'haimeng@usc.edu':'316cca1ff42067b9901b6a9e90ca76496e76b4a73139954176c6fe31a45572fcd37089924cbe5c41edb96a9b4c0e92e44451ed350e2a7e45dc809d26cd752eed',\n",
    "          'pokharel@usc.edu' : '21acf454868c89a86938ffcb6b17cc1236f783c6e340937ab3205598608408623893094770f403dd95ba758d9864ef2135eda8f381804787e15e8ab2aedd3ba3',\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify API and Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script checks for how many jobs are available per token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 jobs available for haimeng@usc.edu\n",
      "1 jobs available for pokharel@usc.edu\n"
     ]
    }
   ],
   "source": [
    "#write the email address corresponding to each API, this will help when these APIs expire\n",
    "apiDict = tokens\n",
    "apiInv =dict(map(reversed, apiDict.items()))\n",
    "apitokens = list(apiDict.values())\n",
    "\n",
    "\n",
    "for token in apitokens:\n",
    "    IBMQ.disable_account() #Start with no account loaded\n",
    "    provider = IBMQ.enable_account(token) #Some account must be loaded before we start\n",
    "    backend = provider.backends.ibmq_bogota\n",
    "    available_jobs = backend.job_limit().maximum_jobs - backend.job_limit().active_jobs\n",
    "    print(f\"{available_jobs} jobs available for {apiInv[token]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 20000\n"
     ]
    }
   ],
   "source": [
    "backend.configuration() #max_experiments=75, max_shots=8192\n",
    "max_experiments=backend.configuration().max_experiments\n",
    "max_shots=backend.configuration().max_shots\n",
    "print(max_experiments,max_shots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print backend info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IBMQBackend('ibmq_bogota') from IBMQ(hub='ibm-q', group='open', project='main')>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qiskit.providers.models.backendproperties.BackendProperties"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop=backend.properties()\n",
    "type(prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T1': (0.00010577041880559754,\n",
       "  datetime.datetime(2022, 2, 24, 7, 33, tzinfo=tzlocal())),\n",
       " 'T2': (4.5051195029772205e-05,\n",
       "  datetime.datetime(2022, 2, 21, 21, 56, 2, tzinfo=tzlocal())),\n",
       " 'frequency': (4849848751.340729,\n",
       "  datetime.datetime(2022, 2, 24, 9, 50, 28, tzinfo=tzlocal())),\n",
       " 'anharmonicity': (-325707270.68764627,\n",
       "  datetime.datetime(2022, 2, 24, 9, 50, 28, tzinfo=tzlocal())),\n",
       " 'readout_error': (0.07250000000000001,\n",
       "  datetime.datetime(2022, 2, 23, 21, 46, 3, tzinfo=tzlocal())),\n",
       " 'prob_meas0_prep1': (0.09240000000000004,\n",
       "  datetime.datetime(2022, 2, 23, 21, 46, 3, tzinfo=tzlocal())),\n",
       " 'prob_meas1_prep0': (0.0526,\n",
       "  datetime.datetime(2022, 2, 23, 21, 46, 3, tzinfo=tzlocal())),\n",
       " 'readout_length': (5.048888888888889e-06,\n",
       "  datetime.datetime(2022, 2, 23, 21, 46, 3, tzinfo=tzlocal()))}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop.qubit_property(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the circuits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to import backend and token information during the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/haimeng/LocalProjects/IBM-PMME/IBM_data\n"
     ]
    }
   ],
   "source": [
    "# print current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "runRecords = '/home/haimeng/LocalProjects/IBM-PMME/Data/records/info/' #information about each job is stored in this folder\n",
    "\n",
    "def exportJobInfo(usertoken,jobid,filenames,backend):\n",
    "    global runRecords\n",
    "    now = datetime.datetime.now()\n",
    "    qindex = int(filenames[0].split('/')[-1].split('_')[1][-1])\n",
    "    with open(runRecords+jobid + '_' +usertoken+'.csv','w+') as f:\n",
    "        writer = csv.writer(f,delimiter=',')\n",
    "        writer.writerow(['token',token])\n",
    "        writer.writerow(['jobid',jobid])\n",
    "        writer.writerow(['backend',backend.properties().backend_name])\n",
    "        writer.writerow(['qubit',qindex])\n",
    "        prop = backend.properties().qubit_property(qindex)\n",
    "        for key,value in prop.items():\n",
    "            writer.writerow([key,value])\n",
    "        writer.writerow(['circuits'])\n",
    "        for item in filenames:\n",
    "            writer.writerow([item])\n",
    "        # write time stamps\n",
    "        job = backend.retrieve_job(runId)\n",
    "        writer.writerow(['job_creation',job._time_per_step['CREATING']])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ibmq_bogota'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backend_info = backend.properties().to_dict() \n",
    "backend_info['backend_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to check for available tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 jobs available for haimeng@usc.edu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'316cca1ff42067b9901b6a9e90ca76496e76b4a73139954176c6fe31a45572fcd37089924cbe5c41edb96a9b4c0e92e44451ed350e2a7e45dc809d26cd752eed'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    " \n",
    "#Select a available token to send the run to\n",
    "#With the current setup, loading and unloading a token takes sometime\n",
    "#sequentially check each token for availability will increase loadtime for tokens that are near the end\n",
    "#so given a list of tokens, everytime a job is sent to a token, that token will be sent to the end\n",
    "def availableToken():\n",
    "    global provider, backend, apitokens\n",
    "    token = apitokens[0]\n",
    "    available_jobs = backend.job_limit().maximum_jobs - backend.job_limit().active_jobs\n",
    "    if available_jobs > 1:\n",
    "        print(f'{available_jobs} jobs available for {apiInv[token]}')\n",
    "        return token\n",
    "\n",
    "    #if the first token has no availability then we will continue below\n",
    "    apitokens.append(apitokens.pop(0))\n",
    "    for token in apitokens:\n",
    "        IBMQ.disable_account() \n",
    "        provider = IBMQ.enable_account(token) \n",
    "        backend = provider.backends.ibmq_bogota\n",
    "        available_jobs = backend.job_limit().maximum_jobs - backend.job_limit().active_jobs\n",
    "        if available_jobs > 1:\n",
    "            print(f'{available_jobs} jobs available for {apiInv[token]}')\n",
    "            apitokens.insert(0, apitokens.pop(apitokens.index(token)))\n",
    "            return token\n",
    "\n",
    "availableToken()   \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually doing the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with empty containers\n",
    "#dont run this block if you already have a list of runs you want to continue\n",
    "\n",
    "runDict = {} #matches each batch to the job token\n",
    "jobDict = {} #matches each batch to the entire job object\n",
    "jobsFound = set([]) #status is updated when checked\n",
    "jobsDone = set([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ibmq_bogota'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backend.properties().backend_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 jobs available for haimeng@usc.edu\n",
      "JobStatus.VALIDATING\n",
      "Batch 0 has been sent\n",
      "3 jobs available for haimeng@usc.edu\n",
      "JobStatus.VALIDATING\n",
      "Batch 1 has been sent\n",
      "2 jobs available for haimeng@usc.edu\n",
      "JobStatus.VALIDATING\n",
      "Batch 2 has been sent\n",
      "4 jobs available for haimeng@usc.edu\n",
      "JobStatus.VALIDATING\n",
      "Batch 3 has been sent\n",
      "3 jobs available for haimeng@usc.edu\n",
      "JobStatus.VALIDATING\n",
      "Batch 4 has been sent\n",
      "{0: ['316cca1ff42067b9901b6a9e90ca76496e76b4a73139954176c6fe31a45572fcd37089924cbe5c41edb96a9b4c0e92e44451ed350e2a7e45dc809d26cd752eed', '6227cdad9e029c004a0de634'], 1: ['316cca1ff42067b9901b6a9e90ca76496e76b4a73139954176c6fe31a45572fcd37089924cbe5c41edb96a9b4c0e92e44451ed350e2a7e45dc809d26cd752eed', '6227d0bc87f7023b4d54a38e'], 2: ['316cca1ff42067b9901b6a9e90ca76496e76b4a73139954176c6fe31a45572fcd37089924cbe5c41edb96a9b4c0e92e44451ed350e2a7e45dc809d26cd752eed', '6227d189a7d9a619ddf2cbb1'], 3: ['316cca1ff42067b9901b6a9e90ca76496e76b4a73139954176c6fe31a45572fcd37089924cbe5c41edb96a9b4c0e92e44451ed350e2a7e45dc809d26cd752eed', '6227d23c6d026a7c2ca35eac'], 4: ['316cca1ff42067b9901b6a9e90ca76496e76b4a73139954176c6fe31a45572fcd37089924cbe5c41edb96a9b4c0e92e44451ed350e2a7e45dc809d26cd752eed', '6227d2e050a9afafc99fc2ef']}\n"
     ]
    }
   ],
   "source": [
    "#start runs\n",
    "#generally we want to run all the batchFiles, but we can also choose to run only some of them:\n",
    "#todoFiles = [batchFiles[3]]\n",
    "jobsNotFound = list(set(range(0, len(batchFiles))) - jobsFound)\n",
    "\n",
    "# todoFiles = batchFiles[0::]\n",
    "# for runFiles in todoFiles:\n",
    "for n in jobsNotFound[0::]:\n",
    "    \n",
    "    runFiles = batchFiles[n]\n",
    "    token = availableToken()\n",
    "\n",
    "    allQasmList = [QuantumCircuit.from_qasm_file(file) for file in runFiles] #this needs to edited if the batch files also contain directory\n",
    "    allCircuits= assemble(allQasmList, backend, shots=8192)\n",
    "\n",
    "    job_current = backend.run(allCircuits)\n",
    "    print(job_current.status())\n",
    "\n",
    "    runId = job_current.job_id()\n",
    "#     runTokens.append(token)\n",
    "#     runIds.append(runId)\n",
    "#         runDict[batchFiles.index(runFiles)] = [token, runId] #note that the index still refers to the original batchFiles\n",
    "    runDict[n] = [token, runId]\n",
    "    #as retrieve job is not working temporarily I will save job_current in a dictionary as well\n",
    "#     jobDict[batchFiles.index(runFiles)] = job_current\n",
    "    jobDict[n] = job_current\n",
    "    print(f\"Batch {batchFiles.index(runFiles)} has been sent\")\n",
    "\n",
    "    exportJobInfo(token, runId, batchFiles[0], backend)\n",
    "\n",
    "\n",
    "print(runDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['316cca1ff42067b9901b6a9e90ca76496e76b4a73139954176c6fe31a45572fcd37089924cbe5c41edb96a9b4c0e92e44451ed350e2a7e45dc809d26cd752eed',\n",
       "  '6227cdad9e029c004a0de634'],\n",
       " 1: ['316cca1ff42067b9901b6a9e90ca76496e76b4a73139954176c6fe31a45572fcd37089924cbe5c41edb96a9b4c0e92e44451ed350e2a7e45dc809d26cd752eed',\n",
       "  '6227d0bc87f7023b4d54a38e'],\n",
       " 2: ['316cca1ff42067b9901b6a9e90ca76496e76b4a73139954176c6fe31a45572fcd37089924cbe5c41edb96a9b4c0e92e44451ed350e2a7e45dc809d26cd752eed',\n",
       "  '6227d189a7d9a619ddf2cbb1'],\n",
       " 3: ['316cca1ff42067b9901b6a9e90ca76496e76b4a73139954176c6fe31a45572fcd37089924cbe5c41edb96a9b4c0e92e44451ed350e2a7e45dc809d26cd752eed',\n",
       "  '6227d23c6d026a7c2ca35eac'],\n",
       " 4: ['316cca1ff42067b9901b6a9e90ca76496e76b4a73139954176c6fe31a45572fcd37089924cbe5c41edb96a9b4c0e92e44451ed350e2a7e45dc809d26cd752eed',\n",
       "  '6227d2e050a9afafc99fc2ef']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Batch| Q#  | Status\n",
      "| 000 | --- | DONE\n",
      "| 001 | --- | DONE\n",
      "| 002 | --- | DONE\n",
      "| 003 | --- | DONE\n",
      "| 004 | --- | DONE\n",
      "5 jobs found: {0, 1, 2, 3, 4}\n",
      "5 jobs done: {0, 1, 2, 3, 4}\n"
     ]
    }
   ],
   "source": [
    "# import sleep\n",
    "jobsNotDone = list(set(runDict.keys()) - jobsDone)\n",
    "\n",
    "def loadToken(token):\n",
    "    global provider, backend\n",
    "    if(not IBMQ.active_account()):\n",
    "        IBMQ.load_account()\n",
    "    IBMQ.disable_account() \n",
    "    provider = IBMQ.enable_account(token) \n",
    "    backend = provider.backends.ibmq_bogota\n",
    "    return None\n",
    "\n",
    "print(\"|Batch| Q#  | Status\")\n",
    "for job in jobsNotDone:\n",
    "#     try:\n",
    "    [token, job_id] = runDict[job]\n",
    "    loadToken(token)\n",
    "\n",
    "    #get job from dictionary instead of retrieve job as that function is broken for now\n",
    "#         job_data = backend.retrieve_job(job_id)\n",
    "    #alternatively get job from the jobD|ict\n",
    "    if job in jobDict:\n",
    "        job_data = jobDict[job]\n",
    "    else:\n",
    "        job_data = backend.retrieve_job(job_id)\n",
    "    #print(f\"Batch {job} is {job_data.status()}\")\n",
    "\n",
    "    jobsFound.add(job)\n",
    "    qno = '---'\n",
    "    if str(job_data.status()) == 'JobStatus.QUEUED':\n",
    "        #print(f'queue number is {job_data.queue_info().position}')\n",
    "        qno = str(job_data.queue_info().position).zfill(3)\n",
    "\n",
    "    if str(job_data.status()) == 'JobStatus.DONE':\n",
    "        jobsDone.add(job)\n",
    "\n",
    "    st = str(job_data.status()).split('.')[1]\n",
    "    jno = str(job).zfill(3)\n",
    "    print(f'| {jno} | {qno} | {st}')\n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "print(f'{len(jobsFound)} jobs found: {jobsFound}')\n",
    "print(f'{len(jobsDone)} jobs done: {jobsDone}')\n",
    "# if some batches are showing network errors, run only those batches again\n",
    "# try, excess commands above force the loop to continue even when some batches show errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobDict[4].error_message()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Data (Run after jobs have completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/haimeng/LocalProjects/IBM-PMME/Circuits/ibmq_bogota/20220302/MeasMainqFreeLongXY4_Q0_tetra3_QS4_ZminusState/MeasError_Mitigate_20220302_ibmq_bogota_ZplusState_obsZ.qasm\n",
      "/home/haimeng/LocalProjects/IBM-PMME/Circuits/ibmq_bogota/20220302/MeasMainqFreeLongXY4_Q0_tetra3_QS4_ZminusState\n"
     ]
    }
   ],
   "source": [
    "filename = batchFiles[0][-1]\n",
    "print(filename)\n",
    "print(os.path.dirname(filename))\n",
    "run=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/haimeng/LocalProjects/IBM-PMME/Circuits/ibmq_bogota/20220302/MeasMainqFreeLongXY4_Q0_randomState_QS4_ZplusState/MeasError_Mitigate_20220302_ibmq_bogota_ZplusState_obsZ.qasm'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultRecords = '/home/haimeng/LocalProjects/IBM-PMME/Data/records/results/'\n",
    "datadir = '/home/haimeng/LocalProjects/IBM-PMME/Data/raw'\n",
    "device = 'ibmq_bogota'\n",
    "datestr = '20220308'\n",
    "if not os.path.exists(resultRecords):\n",
    "        os.makedirs(resultRecords)\n",
    "\n",
    "#job results are returned a list of dictionaries and they will have the same order as the order of the files in that batch\n",
    "# filenames given here should also include the folder names as well\n",
    "def exportBatchJob(filenames, token, job_id, index):\n",
    "    loadToken(token)\n",
    "    #job_data = backend.retrieve_job(job_id)\n",
    "    if job in jobDict:\n",
    "        job_data = jobDict[job]\n",
    "        print('found token')\n",
    "    else:\n",
    "        job_data = backend.retrieve_job(job_id)\n",
    "        \n",
    "    # write finish time\n",
    "    with open(runRecords+job_id + '_' +token+'.csv','a') as f:\n",
    "        writer = csv.writer(f,delimiter=',')\n",
    "        writer.writerow(['job_finish_time',job_data._time_per_step['COMPLETED']])\n",
    "        \n",
    "    with open(resultRecords + f'{job_id}_{token}_results.txt', 'w') as f:\n",
    "        f.write(str(job_data.result().to_dict()))\n",
    "    \n",
    "    for i in range(0, len(filenames)):\n",
    "        result = job_data.result().get_counts()[i]\n",
    "        exportResult(token, job_id, i, filenames[i], result,index)\n",
    "        \n",
    "        \n",
    "#results will be in the form of dictionary\n",
    "#filename here should also include the foldernames\n",
    "def exportResult(token, job_id, circNo, filename, result,index):\n",
    "#     print(filename)\n",
    "    directory = datadir + '/' + device +'/' + datestr + f'/{runtype}_QS={QS}_job{index}/'\n",
    "    filename_new = os.path.basename(filename).split('.qasm')[0].split('_')\n",
    "    \n",
    "    if 'MeasMainqFree' in filename_new:\n",
    "        filename_new.insert(5,str(index))\n",
    "    file = directory + '_'.join(filename_new) + f'_{job_id}.txt'\n",
    "    if not os.path.exists(os.path.dirname(file)):\n",
    "        os.makedirs(os.path.dirname(file))\n",
    "        \n",
    "    \n",
    "    with open(file, 'w') as f:\n",
    "            f.write(\"usertoken,jobid,circuit_number\\n\")\n",
    "            f.write(f\"{token},{job_id},{circNo}\\n\")\n",
    "            [f.write( '\"'+str(key)+'\"' + ',' + str(value) + '\\n') for key, value in result.items()]\n",
    "    return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found token\n",
      "job 0 has been exported\n",
      "found token\n",
      "job 1 has been exported\n",
      "found token\n",
      "job 2 has been exported\n",
      "found token\n",
      "job 3 has been exported\n",
      "found token\n",
      "job 4 has been exported\n"
     ]
    }
   ],
   "source": [
    "# batchFilesFull = [ [ inputDir + f for f in batch] for batch in batchFiles] #this wont be necessary if the filename have dir\n",
    "for job in list(runDict.keys()):\n",
    "    [token, job_id] = runDict[job]\n",
    "    exportBatchJob(batchFiles[job], token, job_id,index=job)\n",
    "    print(f\"job {job} has been exported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newest_qiskit",
   "language": "python",
   "name": "newest_qiskit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
